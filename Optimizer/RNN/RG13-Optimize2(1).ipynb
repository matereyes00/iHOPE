{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPMmlbkPbCmbXycDgkDKVlg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z_JATVFOOKZA","executionInfo":{"status":"ok","timestamp":1715173056104,"user_tz":-480,"elapsed":270206,"user":{"displayName":"Martina Therese Reyes","userId":"15446499683277916119"}},"outputId":"de404e5a-b4d2-4731-bd57-a0e25847242a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["region = 13\n","mother_directory = f\"/content/drive/MyDrive/MS thesis/[optimize] Training, Testing/RG{region}/\"\n","# raw_rg1_clustered = pd.read_csv(\"/content/drive/MyDrive/MS thesis/preliminary site selection/CALABARZON/calabarzon_clusters.csv\")\n","raw_rg1_clustered = pd.read_csv(mother_directory + \"PCF_data.csv\")\n","# use pcf data nalang para you dont get nans for sure?\n","\n","neighbors_df = pd.read_csv(mother_directory + 'neighbours.csv')\n","candidate_sites = pd.read_csv(mother_directory + \"candidate_sites.csv\")\n","candidate_sites\n","\n","'''AGGREGATING THE POPULATION'''\n","# Assuming df is your DataFrame\n","# vp =  raw_rg1_clustered['popden_chi'] + raw_rg1_clustered['popden_eld'] + raw_rg1_clustered['popden_wom'] + raw_rg1_clustered['popden_you'] + raw_rg1_clustered['popden_w_1'] + raw_rg1_clustered['popden_you']\n","# gen = raw_rg1_clustered['popden_all'] - vp\n","# all = vp + gen\n","# raw_rg1_clustered['total_population'] = all\n","# raw_rg1_clustered.columns\n","\n","# raw_rg1_clustered = raw_rg1_clustered.drop(columns=['Unnamed: 0'])\n","neighbors_df.rename(columns={'fid': 'ID'}, inplace=True)\n","# raw_rg1_clustered = raw_rg1_clustered.drop(columns=['HCFAI.1'])\n","raw_rg1_clustered.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QoMoMCoOOzs3","executionInfo":{"status":"ok","timestamp":1715173058559,"user_tz":-480,"elapsed":2461,"user":{"displayName":"Martina Therese Reyes","userId":"15446499683277916119"}},"outputId":"4305e43e-995c-4c81-85bb-20615cb23916"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['popden_chi', 'popden_eld', 'popden_wom', 'popden_you', 'popden_w_1',\n","       'popden_all', 'flood_probability_value', 'rain intensity_value',\n","       'drought_value', 'Distance_to_Nearest_RHU_km', 'HCFAI',\n","       'total_population', 'RHU_Presence', 'ID', 'buildability_landcov',\n","       'Road_Presence', 'POI_Presence', 'Nearest_RHU', 'Cluster'],\n","      dtype='object')"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["# Define the HCI calculation function\n","def HCI_calc(total_ai, total_gi, total_hi, total_ji, total_ki, total_mi,distance, road_bi, POI_ci, landCov_di, hazard1_ei, hazard2_ei, hazard3_ei, rhus_fi):\n","    total_vulnerable = total_gi + total_hi + total_ji + total_ki + total_mi\n","    total_pop = total_ai\n","    population_to_be_served = total_vulnerable + np.maximum(0, total_pop - total_vulnerable)\n","    # Calculate y for the entire Series without using if condition\n","    y = np.where(population_to_be_served == 0, 0, 20000 / ((population_to_be_served) * (distance + rhus_fi)))\n","    mc = np.tanh(y)\n","    w_bi = 0.3 # roads\n","    w_ci = 0.2 # POIs\n","    w_di = 0.5 # land cov\n","    b = (POI_ci * w_ci) + (road_bi * w_bi) + (landCov_di * w_di)\n","    # Normalize each factor\n","    rain_intensity_normalized = (hazard1_ei - hazard1_ei.min()) / (hazard1_ei.max() - hazard1_ei.min())\n","    flood_probability_normalized = (hazard2_ei - hazard2_ei.min()) / (hazard2_ei.max() - hazard2_ei.min())\n","    drought_mean_normalized = (hazard3_ei - hazard3_ei.min()) / (hazard3_ei.max() - hazard3_ei.min())\n","    w_rain = 0.4\n","    w_flood = 0.3\n","    w_drought = 0.3\n","    c = (w_rain * rain_intensity_normalized) + (w_flood * flood_probability_normalized) + (w_drought * drought_mean_normalized)\n","    f = b - c\n","    f = np.tanh(f)\n","    hci = mc * f\n","    hcfai = (1 + np.tanh(hci / 2)) / 2  # Sigmoid function\n","    return hcfai\n","\n","# Computing overall HCFAI using SUM\n","def overallHCFAI(region_df):\n","    HCFAI_overall = region_df['HCFAI'].sum()\n","    return HCFAI_overall\n","\n","# Select top N candidate sites based on HCFAI score computed from region_df\n","def selectTopSites(candidate_sites, region_df, n):\n","    # Merge candidate_sites with region_df based on a common identifier (e.g., ID)\n","    # print(f\"Region df: {region_df.columns}\")\n","    # print(f\"Candidate sites: {candidate_sites.columns}\")\n","    # Define the columns to merge\n","    # columns_to_merge = ['ID', 'barangay_name', 'city_name', 'province_name',\n","    #                     'popden_chi', 'popden_eld', 'popden_wom', 'popden_you', 'popden_w_1',\n","    #                     'popden_all', 'flood_probability_value', 'rain intensity_value',\n","    #                     'drought_value', 'buildability_landcov', 'RHU_Presence',\n","    #                     'Road_Presence', 'POI_Presence', 'Nearest_RHU',\n","    #                     'Distance_to_Nearest_RHU_km', 'total_population']\n","    columns_to_merge = ['ID',\n","                        'popden_chi', 'popden_eld', 'popden_wom', 'popden_you', 'popden_w_1',\n","                        'popden_all', 'flood_probability_value', 'rain intensity_value',\n","                        'drought_value', 'buildability_landcov', 'RHU_Presence',\n","                        'Road_Presence', 'POI_Presence', 'Nearest_RHU',\n","                        'Distance_to_Nearest_RHU_km', 'total_population']\n","\n","    # Merge only the specified columns from region_df to candidate_sites\n","    merged_sites = candidate_sites.merge(region_df[columns_to_merge], on='ID', how='left')\n","    # print(f\"Merged: {merged_sites.columns}\")\n","    # Create a new DataFrame without the column 'Unnamed: 0'\n","    # merged_sites = candidate_sites.merge(region_df, on='ID', how='left')\n","    # Compute HCFAI scores for candidate sites using data from region_df\n","    merged_sites['HCFAI'] = HCI_calc(merged_sites['popden_all'],\n","                                      merged_sites['popden_chi'],\n","                                      merged_sites['popden_eld'],\n","                                      merged_sites['popden_wom'],\n","                                      merged_sites['popden_you'],\n","                                      merged_sites['popden_w_1'],\n","                                      merged_sites['Distance_to_Nearest_RHU_km'],\n","                                      merged_sites['Road_Presence'],\n","                                      merged_sites['POI_Presence'],\n","                                      merged_sites['buildability_landcov'],\n","                                      merged_sites['rain intensity_value'],\n","                                      merged_sites['flood_probability_value'],\n","                                      merged_sites['drought_value'],\n","                                      merged_sites['RHU_Presence'],\n","                                     )\n","\n","    # Fill missing values from region_df to candidate_sites\n","    missing_cols = [col for col in region_df.columns if col != ['ID']]\n","    for col in missing_cols:\n","        # Set the index of region_df to 'ID' if it's not already set\n","        if 'ID' not in region_df.columns:\n","            region_df.set_index('ID', inplace=True)\n","        # Fill missing values in merged_sites using values from region_df\n","        merged_sites[col] = merged_sites[col].fillna(region_df[col])\n","\n","    # Select top N sites based on computed HCFAI scores\n","    top_sites = merged_sites.sort_values(by='HCFAI', ascending=False).head(n)\n","    return top_sites\n","\n","# Remove adjacent sites from the list of candidate sites\n","def removeAdjacentSites(region_df, candidate_sites, selected_sites, neighbors_df):\n","    # Get the indices of hexagons with existing health facilities\n","    idx_with_RHU = region_df[region_df['RHU_Presence'] == 1]\n","    # Initialize a set to store adjacent sites\n","    adjacent_sites = set()\n","    # Add neighbors of selected sites\n","    for site_id in selected_sites['ID']:\n","      if site_id in neighbors_df['ID'].values:\n","          neighbors = neighbors_df.loc[neighbors_df['ID'] == site_id, 'neighbours'].iloc[0]\n","          adjacent_sites.update(neighbors.split(','))\n","    # Add hexagons with existing health facilities and the selected sites themselves\n","    adjacent_sites.update(idx_with_RHU['ID'])\n","    adjacent_sites.update(selected_sites['ID'])\n","    # Convert the adjacent sites to integers\n","    adjacent_sites = [int(site) for site in adjacent_sites]\n","    # Remove adjacent sites from the candidate sites\n","    candidate_sites = candidate_sites[~candidate_sites['ID'].isin(adjacent_sites)]\n","    # Recalculate HCFAI values for selected sites using data from region_df\n","    selected_sites['HCFAI'] = HCI_calc(selected_sites['popden_all'], selected_sites['popden_chi'],\n","                                       selected_sites['popden_eld'], selected_sites['popden_wom'],\n","                                       selected_sites['popden_you'], selected_sites['popden_w_1'],\n","                                       selected_sites['Distance_to_Nearest_RHU_km'],\n","                                       selected_sites['Road_Presence'], selected_sites['POI_Presence'],\n","                                       selected_sites['buildability_landcov'], selected_sites['rain intensity_value'],\n","                                       selected_sites['flood_probability_value'], selected_sites['drought_value'],\n","                                       selected_sites['RHU_Presence'])\n","    return candidate_sites, selected_sites, idx_with_RHU\n","\n","# Optimize the selection of health facility sites\n","def optimize(region_df, candidate_sites, neighbors_df, num_facilities):\n","  # Print original HCFAI\n","  original_HCFAI = overallHCFAI(region_df)\n","  print(\"Original HCFAI:\", original_HCFAI)\n","  selected_sites = pd.DataFrame(columns=region_df.columns)\n","  while len(selected_sites) < num_facilities:\n","    # Select top candidate sites\n","    top_sites = selectTopSites(candidate_sites, region_df, num_facilities - len(selected_sites))\n","    # Remove adjacent sites from candidate list and update HCFAI for selected sites\n","    candidate_sites, top_sites, idx_with_RHU = removeAdjacentSites(region_df, candidate_sites, top_sites, neighbors_df)\n","    # Add selected sites to the final list\n","    selected_sites = pd.concat([selected_sites, top_sites])\n","\n","    # Calculate HCFAI for the remaining sites in region_df\n","    remaining_sites = region_df[~region_df['ID'].isin(selected_sites['ID'])]\n","    remaining_HCFAI = overallHCFAI(remaining_sites)\n","    selected_sites_HCFAI = overallHCFAI(selected_sites)\n","\n","    # Calculate updated overall HCFAI\n","    updated_HCFAI = remaining_HCFAI + selected_sites_HCFAI\n","    print(\"Updated HCFAI:\", updated_HCFAI)\n","\n","    if len(selected_sites) == num_facilities:\n","        print(\"Accept!!!!!!!!!!!!!!\")\n","        return selected_sites, idx_with_RHU, original_HCFAI, updated_HCFAI\n","    else:\n","        print(\"Reject!!!!!!!!!!!!!!\")\n","        print(\"Selected sites:\", len(selected_sites))\n","\n","  return selected_sites, idx_with_RHU, original_HCFAI, updated_HCFAI"],"metadata":{"id":"8FjRyfaPOMMH","executionInfo":{"status":"ok","timestamp":1715173058560,"user_tz":-480,"elapsed":7,"user":{"displayName":"Martina Therese Reyes","userId":"15446499683277916119"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["print(f\"Candidate sites: {len(candidate_sites)}\")\n","# Optimize selection of health facility sites\n","selected_facilities, hex_with_RHU, og_HCFAI, updated_HCFAI = optimize(raw_rg1_clustered, candidate_sites, neighbors_df, 1)\n","print(selected_facilities.to_string(index=False))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yu0uAK3JOQSG","executionInfo":{"status":"ok","timestamp":1715173165056,"user_tz":-480,"elapsed":416,"user":{"displayName":"Martina Therese Reyes","userId":"15446499683277916119"}},"outputId":"41cf339d-596c-48de-b2eb-65bee7df2c3a"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Candidate sites: 2201\n","Original HCFAI: 1919.5258770785804\n","Updated HCFAI: 1918.9281232230178\n","Accept!!!!!!!!!!!!!!\n"," popden_chi  popden_eld  popden_wom  popden_you  popden_w_1  popden_all  flood_probability_value  rain intensity_value  drought_value  Distance_to_Nearest_RHU_km HCFAI  total_population RHU_Presence      ID buildability_landcov Road_Presence POI_Presence Nearest_RHU Cluster  pred_y  actual_y\n","        0.0         0.0         0.0         0.0         0.0    0.010407                 0.568073              0.022628       0.560882                    0.692577   NaN          0.010407            0 3460374                    1             0            0     3443757       0     1.0       0.0\n"]}]},{"cell_type":"code","source":["selected_facilities = list(selected_facilities['ID'])\n","hex_with_RHU = list(hex_with_RHU['ID'])\n","hex_with_RHU\n","print(f\"Optimal sites: {len(selected_facilities)}\")\n","print(f\"Sites with RHUs: {len(hex_with_RHU)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rc1hvSoHX9UP","executionInfo":{"status":"ok","timestamp":1715173166075,"user_tz":-480,"elapsed":4,"user":{"displayName":"Martina Therese Reyes","userId":"15446499683277916119"}},"outputId":"88a42fc6-13c0-45e0-bd2c-4f17c3a48065"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Optimal sites: 1\n","Sites with RHUs: 5\n"]}]},{"cell_type":"code","source":["selected_facilities"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M_yYmBgFCXA5","executionInfo":{"status":"ok","timestamp":1715173171402,"user_tz":-480,"elapsed":413,"user":{"displayName":"Martina Therese Reyes","userId":"15446499683277916119"}},"outputId":"0cc17d1d-d563-45b9-a1fa-c3eb54ab5e74"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[3460374]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["hex_with_RHU"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gmLsg8Y9YJYk","executionInfo":{"status":"ok","timestamp":1715173172889,"user_tz":-480,"elapsed":4,"user":{"displayName":"Martina Therese Reyes","userId":"15446499683277916119"}},"outputId":"bbc2ac4e-7ee1-42cd-ffbd-e848710228d7"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[3362142, 3398135, 3407800, 3432642, 3443757]"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["# Validation"],"metadata":{"id":"iUd-Ce0SJXjz"}},{"cell_type":"code","source":["import random\n","import pandas as pd\n","\n","def getRandom48(candidate_sites, random_seed=None):\n","    \"\"\"\n","    Randomly select 48 sites from the candidate sites DataFrame.\n","\n","    Parameters:\n","        candidate_sites (DataFrame): DataFrame containing information about all candidate sites.\n","        random_seed (int): Random seed for reproducibility.\n","\n","    Returns:\n","        DataFrame: Randomly selected 48 sites DataFrame.\n","    \"\"\"\n","    if random_seed is not None:\n","        random.seed(random_seed)\n","    candidate_sites_shuffled = candidate_sites.sample(frac=1).reset_index(drop=True)\n","    random_48 = candidate_sites_shuffled.sample(n=48)\n","    return random_48\n","\n","\n","def randomize(region_df, candidate_sites, random_seed):\n","    \"\"\"\n","    Randomize the selection of 48 sites and update the overall HCFAI value.\n","    Parameters:\n","        region_df (DataFrame): DataFrame containing information about all sites in the region.\n","    Returns:\n","        tuple: Tuple containing the updated overall HCFAI value and the IDs of randomly selected sites.\n","    \"\"\"\n","    HCFAI_overall_before = overallHCFAI(region_df)\n","    # print(\"Overall HCFAI (before randomization): \", HCFAI_overall_before)\n","    random_48 = getRandom48(candidate_sites, random_seed)\n","    columns_to_merge = ['ID',\n","                        'popden_chi', 'popden_eld', 'popden_wom', 'popden_you', 'popden_w_1',\n","                        'popden_all', 'flood_probability_value', 'rain intensity_value',\n","                        'drought_value', 'buildability_landcov', 'RHU_Presence',\n","                        'Road_Presence', 'POI_Presence', 'Nearest_RHU',\n","                        'Distance_to_Nearest_RHU_km', 'HCFAI', 'total_population']\n","    merged_sites = random_48.merge(region_df[columns_to_merge], on='ID', how='left')\n","    missing_cols = [col for col in region_df.columns if col != ['ID']]\n","    for col in missing_cols:\n","        if 'ID' not in region_df.columns:\n","            region_df.set_index('ID', inplace=True)\n","        merged_sites[col] = merged_sites[col].fillna(region_df[col])\n","    # Calculate HCFAI for the remaining sites in region_df\n","    remaining_sites = region_df[~region_df['ID'].isin(merged_sites['ID'])]\n","    remaining_HCFAI = overallHCFAI(remaining_sites)\n","    print(remaining_HCFAI)\n","    selected_sites_HCFAI = overallHCFAI(merged_sites)\n","    print(selected_sites_HCFAI)\n","\n","    # Calculate updated overall HCFAI\n","    updated_HCFAI = remaining_HCFAI + selected_sites_HCFAI\n","    # print(f\"Updated HCFAI: \", updated_HCFAI)\n","    return updated_HCFAI, random_48['ID'].tolist()\n","\n","# Example usage\n","rdm_hcfai = []\n","rdm_points = []\n","for i in range(10):\n","    random_seed = i  # Use a different random seed for each iteration\n","    rdm_ovHCFAI, rdm_48 = randomize(raw_rg1_clustered, candidate_sites, random_seed)\n","    rdm_hcfai.append(rdm_ovHCFAI)\n","    rdm_points.append(rdm_48)\n","\n","rdm_HCFAI_avg = sum(rdm_hcfai) / len(rdm_hcfai)\n","highest_rdm_HCFAI = max(rdm_hcfai)\n","# print(\"Average HCFAI after randomization: \", rdm_HCFAI_avg)\n","\n","Results_rdmsum = pd.DataFrame({\n","    'Hex IDs': rdm_points,\n","    'HCFAI': rdm_hcfai\n","})\n","\n","print(\"=========== OG HCFAI RESULTS ===========\")\n","print(\"ORIGINAL HCFAI\", og_HCFAI)\n","print(\"=========== RANDOM HCFAI RESULTS ===========\")\n","# print(\"RANDOMIZED HCFAI [All, 10-fold]\", rdm_hcfai)\n","print(\"RANDOMIZED HCFAI [10-fold]: \", highest_rdm_HCFAI)\n","# print(\"RANDOMIZED HCFAI AVG[10 fold]: \", rdm_HCFAI_avg)\n","print(\"=========== OPTIMIZED HCFAI RESULTS ===========\")\n","print(\"OPTIMIZED HCFAI \", updated_HCFAI)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G1wnln4zJWXq","executionInfo":{"status":"ok","timestamp":1715173176917,"user_tz":-480,"elapsed":398,"user":{"displayName":"Martina Therese Reyes","userId":"15446499683277916119"}},"outputId":"31ff8f00-2014-4b8a-be17-ef17ade0f632"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["1896.1217526894675\n","23.404124389113285\n","1896.018379272759\n","23.507497805821526\n","1896.4250421361312\n","23.100834942449218\n","1897.997150938867\n","21.528726139713573\n","1897.2473778269182\n","22.278499251662318\n","1897.2700869968717\n","22.255790081708838\n","1896.7358251885646\n","22.790051890015675\n","1897.2519269017366\n","22.27395017684389\n","1896.5105568075637\n","23.015320271016495\n","1896.7975912779025\n","22.72828580067793\n","=========== OG HCFAI RESULTS ===========\n","ORIGINAL HCFAI 1919.5258770785804\n","=========== RANDOM HCFAI RESULTS ===========\n","RANDOMIZED HCFAI [10-fold]:  1919.5258770785808\n","=========== OPTIMIZED HCFAI RESULTS ===========\n","OPTIMIZED HCFAI  1918.9281232230178\n"]}]},{"cell_type":"code","source":["hcfai_compare_df =  pd.DataFrame(\n","    {' ': ['SUM'],\n","    'Old HCFAI': og_HCFAI,\n","     'Randomized HCFAI': highest_rdm_HCFAI,\n","     'Algorithm HCFAI': updated_HCFAI\n","    })\n","hcfai_compare_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":80},"id":"IKCvevdlbngw","executionInfo":{"status":"ok","timestamp":1715173177292,"user_tz":-480,"elapsed":8,"user":{"displayName":"Martina Therese Reyes","userId":"15446499683277916119"}},"outputId":"d493f36c-2d6e-41a1-f6c7-29ce831e73ac"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          Old HCFAI  Randomized HCFAI  Algorithm HCFAI\n","0  SUM  1919.525877       1919.525877      1918.928123"],"text/html":["\n","  <div id=\"df-53e13e24-3dc1-421e-9057-33403134cfa4\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>Old HCFAI</th>\n","      <th>Randomized HCFAI</th>\n","      <th>Algorithm HCFAI</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>SUM</td>\n","      <td>1919.525877</td>\n","      <td>1919.525877</td>\n","      <td>1918.928123</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53e13e24-3dc1-421e-9057-33403134cfa4')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-53e13e24-3dc1-421e-9057-33403134cfa4 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-53e13e24-3dc1-421e-9057-33403134cfa4');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"hcfai_compare_df","summary":"{\n  \"name\": \"hcfai_compare_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \" \",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"SUM\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Old HCFAI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1919.5258770785804,\n        \"max\": 1919.5258770785804,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1919.5258770785804\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Randomized HCFAI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1919.5258770785808,\n        \"max\": 1919.5258770785808,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1919.5258770785808\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Algorithm HCFAI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1918.9281232230178,\n        \"max\": 1918.9281232230178,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1918.9281232230178\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":15}]}]}